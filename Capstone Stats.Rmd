---
title: "Capstone Stats"
author: "Cassandra Parker"
date: "8/16/2019"
output: pdf_document
---


##Statistical Analysis on Capstone

Now that I have cleaned, wrangled and slightly explored my data. Let’s get into the statistical analysis. I have created several different plots in the exploratory analysis. Plunging a little deeper into some statistics from our data, we might find some more insightful information. 

```{r}
dat_stats <- read.csv("capdat.csv")
```

Now, the libraries that are necessary to show the skills learned are loaded into are loaded.

```{r}
library(tidyverse)
```


Lets first create a box plot for the standard scores and scores.

```{r}
boxplot(Std_Score~Intervention, data = dat_stats)
boxplot(Score~Intervention, data = dat_stats)
```



Scatter plots are good tools to observe the relationships between variables. The data divided by the Intervention type, is plotted showing the particular earned grade by major. 

```{r}
ggplot(dat_stats, aes(x = Grade, y = Major, color=factor(Intervention))) +
  geom_point()
```


Here is a table of the number of students that earned a particular grade is displayed.

```{r}
table(dat_stats$Grade)
```

This particular histogram determines the major that takes the course more frequently, as well as the breakdown of grades by major.Looking at the plots created, there are quite a few majors with very small numbers. We will need to filter the data to eliminate such values later. 

```{r}
dat_hist <- ggplot(dat_stats, aes(Major))
dat_hist + geom_bar(aes(fill=Grade), width = 0.6) + 
  theme(axis.text.x = element_text(angle=65, vjust=0.6)) + 
  labs(title="Frequency of Major with Earned Final Grades") 
```


Let’s first determine the difference in means between the control and treated groups.
I believe it is vital to our data the we find them separately. Thus the means for these groups are calculated for the outcome variable.  We also determine the number of students in each group.  The treatement and control group are labelled 1, 0 respectively. 

```{r}
dat_stats %>%
  dplyr::group_by(Intervention) %>%
  dplyr::summarise(n_students = n(),
            mean_Score = mean(Score),
            std_error = sd(Score) / sqrt(n_students))
```

Also, run the same above code but this time we use the standard score.  The standard score is the standard z-score.

```{r}
dat_stats %>%
  dplyr:: group_by(Intervention) %>%
  dplyr:: summarise(n_students = n(),
            mean_Std_Score = mean(Std_Score),
            std_error = sd(Std_Score) / sqrt(n_students))
```


The mean of the observation, or the entire population might have some value to us later. 

```{r}
mean(dat_stats$Score)
```


 I will also attempt to use a t-test. A t test tells you how signiicant the differences between the score and std_score are. In simplest terms it will let us know if the measured averages of the groups could have happened by chance. If our data gives us low p-values such as  p < 0.05 then, these are good values and indicate our data did not occur by chance. The greater the p value means the more like the intervention just happened "by chance". It can also compare the means of the control and treatment groups to determine if their is a difference in the means. 
```{r}
with(dat_stats, t.test(Std_Score ~ Intervention))
with(dat_stats, t.test(Score ~ Intervention))
```

Our p values are greater than 0.05, which means the grades could have ahppened by chance. 

Lets look at the data, eliminating those majors that are extremely low. Let use the data sat that was created in out exploratory anaylsis new_data. 

Determine the difference in means between the control and treated groups. 
```{r}

new_data %>%
  dplyr::group_by(Intervention) %>%
  dplyr::summarise(n_students = n(),
            AvgScore = mean(Score),
            std_error = sd(Score) / sqrt(n_students))

```

The std_error is quite low, this is actually a good thing. The smaller the error, the less the spread and the more less the spread, the more likely the mean is closest to the population mean. 
 
 
 Now, calculate the differences in means for the standardized score "Std_Score" grouping by treatment (1) and control (0) groups for the outcome variable. 
 
```{r}
new_data %>%
  dplyr:: group_by(Intervention) %>%
  dplyr:: summarise(n_students = n(),
            AvgStdScore = mean(Std_Score),
            std_error = sd(Std_Score) / sqrt(n_students))
```


 
 Again a t test tells you how signiicant the differences between the score and std_score are.  
 
```{r}
with(new_data, t.test(Std_Score ~ Intervention))
with(new_data, t.test(Score ~ Intervention))
```


Our results have a bit of a difference. I anticiapted the p would be less than 0.05.Our p value is quite higher than from our raw data.  Could the intevention grades just happen by chance? Perhaps we can do a variance test as well to double check. 
```{r}
with(new_data, var.test(Std_Score, Score))
```

The variance looks ood and there is a small interval. At this time we can move onto to the propensity portion using MatchIt. Guiding thru MatchIt, there was toons of information that makes this the perfect package to utlize. 
 
 MatchIt implements the suggestions for improving parametric statistical models and reducing model dependence.  When matching select duplicate observations from our data, hence this must be done without inducing bias and the is no dependcencey on the outome variable. "The simplest way to obtain good matches is to use one-to-one exact matching, which pairs each treated unit with one control unit for which the values of Xi are identical. However, with many covariates and finite numbers of potential matches, sufficient exact matches often cannot be found." 
 
 For that reason the nearest neighbor in MatchIt will be more applicable. Nearest neighbor matching selects the r best control matches for each individual
in the treatment group (excluding those discarded using the discard option). Matching is done using a distance measure specified by the distance option. 

